{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from random import uniform\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria = 'trucha'#'mezcla torta' #'cheesecake' #'mezcla pastel' #'postres'\n",
    "length = 0\n",
    "\n",
    "iteration = 0\n",
    "max_iter = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping de almacenes Éxito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scraping_exito(categoria: object, lugar: object, n_clicks:int = 20):\n",
    "    '''\n",
    "    Esta función recibe una palabra clave y la busca en página exito.com. De allí toma el precio, precio\n",
    "    por gramo y el nombre y retorna los datos de todos los productos que encuentra en un dataframe.\n",
    "    ------------------------------------------------------------------------------------------------------\n",
    "    Args:\n",
    "    categoria: palabra clave que se buscará en la página (object)\n",
    "    \n",
    "    lugar: ciudad en la que buscará los productos disponibles (object)\n",
    "    \n",
    "    n_clicks: cantidad de veces que pedirá que se refresque la página para ver más productos, por defecto\n",
    "    lo hará 20 veces (int)\n",
    "    '''\n",
    "    search_url='https://www.exito.com/{categoria}?_q={categoria}&map=ft'\n",
    "    formulario = 'react-select-2-input'\n",
    "    confirmar = 'exito-geolocation-3-x-primaryButton.shippingaddress-confirmar'\n",
    "    items = '//div[contains(@class, \"galleryItem\")]'\n",
    "    ver_mas = '//div[contains(@class, \"buttonShowMore\")]//button'\n",
    "\n",
    "    xpath_precio = './/div[contains(@class, \"exito-vtex-components-4-x-PricePDP\")]'\n",
    "    xpath_pgramo = './/div[contains(@class, \"exito-vtex-components-4-x-validatePumValue\")]'\n",
    "    xpath_nombre = './/span[contains(@class, \"vtex-store-components-3-x-productBrand\")]'\n",
    "    xpath_href = './/a[contains(@class, \"clearLink\")]'\n",
    "\n",
    "    precio = []\n",
    "    pgramo = []\n",
    "    nombre = []\n",
    "\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "    driver.get(search_url.format(categoria = categoria))\n",
    "    sleep(uniform(8.0, 10.0))\n",
    "    \n",
    "    ########################################################\n",
    "    #fragmento del código del día sin IVA \n",
    "    ########################################################\n",
    "    #sleep(uniform(8.0, 10.0))\n",
    "    #boton = driver.find_element_by_xpath('.//div[contains(@id, \"modal-accept-button\")]/button')\n",
    "    #boton.click()\n",
    "    ########################################################\n",
    "\n",
    "    ubicacion = driver.find_element_by_id(formulario)\n",
    "    ubicacion.send_keys(lugar, Keys.RETURN)\n",
    "    boton = driver.find_element_by_class_name(confirmar)\n",
    "    boton.click()\n",
    "    sleep(uniform(10.0, 15.0))\n",
    "    \n",
    "    if n_clicks > 0:\n",
    "        try:\n",
    "            boton = driver.find_element_by_xpath(ver_mas)\n",
    "        except:\n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "            boton = driver.find_element_by_xpath(ver_mas)\n",
    "    for i in range(n_clicks):\n",
    "        try:\n",
    "            boton.click()\n",
    "            sleep(uniform(10.0, 15.0))\n",
    "            boton = driver.find_element_by_xpath(ver_mas)\n",
    "        except:\n",
    "            try:\n",
    "                driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "                sleep(uniform(10.0, 15.0))\n",
    "                boton = driver.find_element_by_xpath(ver_mas)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "    anuncios = driver.find_elements_by_xpath(items)\n",
    "    for anuncio in anuncios:\n",
    "        try:\n",
    "            precio.append(anuncio.find_element_by_xpath(xpath_precio).text)\n",
    "        except:\n",
    "            precio.append(None)\n",
    "        \n",
    "        try:\n",
    "            pgramo.append(anuncio.find_element_by_xpath(xpath_pgramo).text)\n",
    "        except:\n",
    "            pgramo.append(None)\n",
    "            \n",
    "        try:\n",
    "            nombre.append(anuncio.find_element_by_xpath(xpath_nombre).text)\n",
    "        except:\n",
    "            nombre.append(None)\n",
    "        \n",
    "    driver.quit()\n",
    "    \n",
    "    arr_lugar = np.repeat(lugar, len(nombre))\n",
    "    \n",
    "    fecha = datetime.today().strftime('%Y-%m-%d')\n",
    "    arr_fecha = np.repeat(fecha, len(nombre))\n",
    "    \n",
    "    dict_df = {'nombre': nombre,\n",
    "               'precio': precio,\n",
    "               'precio_por_gramo': pgramo,\n",
    "               'fecha': arr_fecha,\n",
    "               'lugar': arr_lugar,\n",
    "                }\n",
    "    df = pd.DataFrame(dict_df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def buscar_terminos_ciudad(categoria:object, \n",
    "                           lugares:list = ['Bogotá', 'Medellín', 'Barranquilla', 'Cali', 'Cartagena', \n",
    "                                           'Armenia', 'Bello', 'Bucaramanga', 'Chía', 'Cúcuta',\n",
    "                                           'Fusagasuga', 'Ibague', 'La Ceja', 'Manizales', 'Monteria',\n",
    "                                           'Neiva', 'Pasto', 'Pereira', 'Popayán', 'Rionegro', \n",
    "                                           'Santa Marta', 'Sincelejo', 'Soacha', 'Tunja', 'Valledupar', \n",
    "                                           'Villavicencio', 'Zipaquira'], \n",
    "                           n_clicks:int = 20):\n",
    "    '''\n",
    "    Esta función recibe una palabra clave y unas ciudades, y la busca en página exito.com para esas\n",
    "    ciudades. De allí toma el precio, precio por gramo y el nombre y retorna los datos de todos los \n",
    "    productos que encuentra en un dataframe, y un arreglo con todas las ciudades con las que no pudo \n",
    "    completar el proceso.\n",
    "    ------------------------------------------------------------------------------------------------------\n",
    "    Args:\n",
    "    categoria: palabra clave que se buscará en la página (object)\n",
    "    \n",
    "    lugares: ciudades en las que buscará los productos disponibles, por defecto lo hará para todas las\n",
    "    ciudades (object)\n",
    "    \n",
    "    n_clicks: cantidad de veces que pedirá que se refresque la página para ver más productos, por defecto\n",
    "    lo hará 20 veces (int)\n",
    "    '''\n",
    "    errores = []\n",
    "\n",
    "    df_final = pd.DataFrame(columns = ['nombre', 'precio', 'precio_por_gramo', 'fecha', 'lugar'])\n",
    "    for lugar in lugares:\n",
    "        try:\n",
    "            df = scraping_exito(categoria, lugar, n_clicks)\n",
    "            df_final = df_final.append(df, ignore_index = True)\n",
    "            sleep(uniform(10.0, 15.0))\n",
    "        except:\n",
    "            errores.append(lugar)\n",
    "            driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "            driver.quit()\n",
    "            \n",
    "    return df_final, errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = buscar_terminos_ciudad(categoria, n_clicks = 0)\n",
    "df_final = res[0].copy()\n",
    "df_final.to_csv('scraping_de_exito_de_{}.csv'.format(categoria), index = False)\n",
    "\n",
    "while len(res[1]) > length:\n",
    "    res = buscar_terminos_ciudad(categoria, res[1], n_clicks = 0)\n",
    "    df_final = df_final.append(res[0], ignore_index = True)\n",
    "    df_final.to_csv('scraping_de_exito_de_{}.csv'.format(categoria), index = False)\n",
    "    \n",
    "    iteration+=1\n",
    "    if iteration > max_iter:\n",
    "        print('Se alcanzó la máxima cantidad de iteraciones')\n",
    "        break\n",
    "    \n",
    "    \n",
    "print('''\n",
    "Hemos terminado!\n",
    "\n",
    "Se ha descargado la informacion de {} productos\n",
    "'''.format(df_final.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping de almacenes Jumbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scraping_jumbo(categoria: object, pagina: int, max_len:int = 7):\n",
    "    '''\n",
    "    Esta función recibe una palabra clave y la busca en página tiendasjumbo.co. De allí toma \n",
    "    el precio con y sin descuento, el nombre, la marca y el precio por gramo.\n",
    "    Retorna los datos de todos los productos que encuentra en un dataframe.\n",
    "    ------------------------------------------------------------------------------------------------------\n",
    "    Args:\n",
    "    categoria: palabra clave que se buscará en la página (object)\n",
    "    \n",
    "    pagina: página del dom en el que buscará (int)\n",
    "    \n",
    "    max_len: parámetro interno que permite distinguir si el producto está en descuento o no (int)\n",
    "    '''\n",
    "    search_url='https://www.tiendasjumbo.co/{categoria}?_q={categoria}&map=ft&page={pagina}'\n",
    "    black_dom_selector = \"return document.querySelector('impulse-search').shadowRoot.querySelectorAll('div.content')\"\n",
    "\n",
    "    nombre = []\n",
    "    marca = []\n",
    "    pcon_descuento = []\n",
    "    psin_descuento = []\n",
    "    pgramo = []\n",
    "\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "    driver.get(search_url.format(categoria = categoria, pagina = pagina))\n",
    "    sleep(uniform(8.0, 10.0))\n",
    "\n",
    "    items = driver.execute_script(black_dom_selector)\n",
    "    if len(items) == 0:\n",
    "        driver.quit()\n",
    "        raise ValueError('Ya no hay más qué buscar')\n",
    "\n",
    "    for item in items:\n",
    "        features = item.text.split('\\n')\n",
    "        try:\n",
    "            nombre.append(features[0])\n",
    "        except:\n",
    "            nombre.append(None)\n",
    "        \n",
    "        try:\n",
    "            marca.append(features[1])\n",
    "        except:\n",
    "            marca.append(None)\n",
    "    \n",
    "        if len(features) > max_len:\n",
    "            try:\n",
    "                psin_descuento.append(features[2])\n",
    "            except:\n",
    "                psin_descuento.append(None)\n",
    "            \n",
    "            try:\n",
    "                pcon_descuento.append(features[3])\n",
    "            except:\n",
    "                pcon_descuento.append(None)\n",
    "            \n",
    "            try:\n",
    "                pgramo.append(features[4])\n",
    "            except:\n",
    "                pgramo.append(None)\n",
    "        else:\n",
    "            pcon_descuento.append(None)\n",
    "            \n",
    "            try:\n",
    "                psin_descuento.append(features[2])\n",
    "            except:\n",
    "                psin_descuento.append(None)\n",
    "            \n",
    "            try:\n",
    "                pgramo.append(features[3])\n",
    "            except:\n",
    "                pgramo.append(None)\n",
    "\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    fecha = datetime.today().strftime('%Y-%m-%d')\n",
    "    arr_fecha = np.repeat(fecha, len(nombre))\n",
    "    \n",
    "    dict_df = {'nombre': nombre,\n",
    "               'marca': marca,\n",
    "               'precio_sin_descuento': pcon_descuento,\n",
    "               'precio_con_descuento': psin_descuento,\n",
    "               'precio_por_gramo': pgramo,\n",
    "                'fecha': arr_fecha\n",
    "        }\n",
    "    df = pd.DataFrame(dict_df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def buscar_termino(categoria:object):\n",
    "    '''\n",
    "    Esta función busca el término hasta que no haya más productos relacionados a él en la página de almacenes\n",
    "    Jumbo\n",
    "    ------------------------------------------------------------------------------------------------------\n",
    "    Args:\n",
    "    categoria: palabra clave que se buscará en la página (object)\n",
    "    '''\n",
    "    pag = 1\n",
    "    df_final = pd.DataFrame(columns = ['nombre', 'marca', 'precio_sin_descuento', 'precio_con_descuento', 'precio_por_gramo', 'fecha'])\n",
    "    while True:\n",
    "        try:\n",
    "            df = scraping_jumbo(categoria, pag)\n",
    "            df_final = df_final.append(df, ignore_index = True)\n",
    "            pag += 1\n",
    "        except:\n",
    "            print('''\n",
    "            Hemos terminado!\n",
    "            \n",
    "            Se ha descargado la informacion de {} productos\n",
    "            '''.format(df_final.shape[0]))\n",
    "            break\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_17904\\2071218949.py:23: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Hemos terminado!\n",
      "            \n",
      "            Se ha descargado la informacion de 0 productos\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "df_final = buscar_termino(categoria)\n",
    "df_final.to_csv('scraping_de_jumbo_de_{}.csv'.format(categoria), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping de almacenes Euro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_euro(categoria: object, pagina: int):\n",
    "    '''\n",
    "    Esta función recibe una palabra clave y la busca en página eurosupermercados.com.co. De allí toma \n",
    "    el precio y el nombre.\n",
    "    Retorna los datos de todos los productos que encuentra en un dataframe.\n",
    "    ------------------------------------------------------------------------------------------------------\n",
    "    Args:\n",
    "    categoria: palabra clave que se buscará en la página (object)\n",
    "    \n",
    "    pagina: página del dom en el que buscará (int)\n",
    "    '''\n",
    "    search_url='https://www.eurosupermercados.com.co/catalogsearch/result/index/?p={pagina}&q={categoria}'\n",
    "    items = '//div[contains(@class, \"product details product-item-details\")]'\n",
    "    \n",
    "    precio = []\n",
    "    pgramo = []\n",
    "    nombre = []\n",
    "    \n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "    driver.get(search_url.format(categoria = categoria, pagina = pagina))\n",
    "    sleep(uniform(8.0, 10.0))\n",
    "\n",
    "    anuncios = driver.find_elements_by_xpath(items)\n",
    "    for anuncio in anuncios:\n",
    "        \n",
    "        lista_anuncio = anuncio.text.split('\\n')\n",
    "        try:\n",
    "            precio.append(lista_anuncio[0])\n",
    "        except:\n",
    "            precio.append(None)\n",
    "            \n",
    "        try:\n",
    "            nombre.append(lista_anuncio[1])\n",
    "        except:\n",
    "            nombre.append(None)\n",
    "                \n",
    "    driver.quit()\n",
    "\n",
    "    fecha = datetime.today().strftime('%Y-%m-%d')\n",
    "    arr_fecha = np.repeat(fecha, len(nombre))\n",
    "    \n",
    "    dict_df = {'nombre': nombre,\n",
    "               'precio': precio,\n",
    "                'fecha': arr_fecha\n",
    "        }\n",
    "    df = pd.DataFrame(dict_df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def buscar_producto(categoria:object, pag_max: int):\n",
    "    '''\n",
    "    Esta función busca el término por la cantidad de páginas que el usuario indique. Busca en la página de\n",
    "    Euro\n",
    "    ------------------------------------------------------------------------------------------------------\n",
    "    Args:\n",
    "    categoria: palabra clave que se buscará en la página (object)\n",
    "    '''\n",
    "    df_final = pd.DataFrame(columns = ['nombre', 'precio', 'fecha'])\n",
    "    for pag in range(1, pag_max+1):\n",
    "        df = scraping_euro(categoria, pag)\n",
    "        df_final = df_final.append(df, ignore_index = True)\n",
    "            \n",
    "    print('''\n",
    "    Hemos terminado!\n",
    "    \n",
    "    Se ha descargado la informacion de {} productos\n",
    "    '''.format(df_final.shape[0]))\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_17904\\397378575.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_17904\\397378575.py:24: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  anuncios = driver.find_elements_by_xpath(items)\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_17904\\397378575.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_final = df_final.append(df, ignore_index = True)\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome.Is google-chrome installed?\n",
      "Get LATEST chromedriver version for None google-chrome\n",
      "Driver [C:\\Users\\david\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Hemos terminado!\n",
      "    \n",
      "    Se ha descargado la informacion de 90 productos\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "df_final = buscar_producto(categoria, 15)\n",
    "df_final.to_csv('scraping_de_euro_de_{}.csv'.format(categoria), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
